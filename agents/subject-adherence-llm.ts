import { BaseAgent } from "./base-agent"
import { AgentResult, EvaluationData } from "@/types"
import { llmGateway } from "@/lib/llm-gateway"
import * as fs from "fs"
import * as path from "path"

export class ContentQualityLLMAgent extends BaseAgent {
  constructor() {
    super("Content Quality LLM Agent")
  }

  async evaluate(data: any): Promise<AgentResult> {
    const startTime = Date.now()

    try {
      // Read the image file for analysis
      const imagePath = path.join(process.cwd(), "public", data.imagePath)
      let imageContent = ""
      if (fs.existsSync(imagePath)) {
        const imageBuffer = fs.readFileSync(imagePath)
        const base64Image = imageBuffer.toString('base64')
        const mimeType = this.getMimeType(imagePath)
        imageContent = `data:${mimeType};base64,${base64Image}`
      }

      // Get brand context if available
      const brandContext = data.brandContext ? `
**Brand Alignment Context:**
- Brand Alignment Score: ${data.brandContext.alignmentScore}/100
- Brand Alignment Analysis: ${data.brandContext.alignmentReasoning}
- Brand Recommendations: ${data.brandContext.recommendations?.join(', ') || 'None'}
` : ''

      const prompt = `
You are an expert evaluator of AI-generated images for brand content. Evaluate the quality and effectiveness of this generated image by assessing how well it matches the original prompt AND aligns with brand requirements.

**Brand Information:**
- Name: ${data.brand.brandName}
- Style: ${data.brand.style}
- Colors: ${data.brand.colors}
- Vision: ${data.brand.brandVision}
- Voice: ${data.brand.brandVoice}
${brandContext}

**Content Context:**
- Intended for: ${data.channel}
- Generated by: ${data.llmModel}
- Original Prompt: "${data.prompt}"

**Evaluation Criteria:**

1. **Prompt Matching (35%)**: How accurately does the image match what was requested?
   - Subject Fidelity: Does the image contain the requested subject matter?
   - Detail Accuracy: Are specific details from the prompt present?
   - Style Adherence: Does the image match the requested style/artistic direction?
   - Composition Alignment: Does the layout match prompt specifications?

2. **Brand Alignment (35%)**: How well does the image serve brand objectives?
   - Brand Visual Identity: Does it reflect brand colors, style, and aesthetics?
   - Brand Voice Communication: Does it convey the brand's personality and values?
   - Target Audience Resonance: Is it appropriate and engaging for the brand's audience?
   - Market Positioning Support: Does it strengthen the brand's market position?

3. **Content Quality (30%)**: Overall quality and effectiveness of the result?
   - Technical Execution: Image quality, composition, and production values?
   - Visual Impact: Does it effectively communicate and engage?
   - Channel Optimization: Is it optimized for the target platform's requirements?

**Evaluate BOTH: (1) How well the image matches the prompt, AND (2) How well it aligns with brand requirements.**

Provide scores for each criterion and an overall assessment.
Format your response as JSON:
{
  "criteria": {
    "promptMatching": {
      "subjectFidelity": { "score": number, "reasoning": "string" },
      "detailAccuracy": { "score": number, "reasoning": "string" },
      "styleAdherence": { "score": number, "reasoning": "string" },
      "compositionAlignment": { "score": number, "reasoning": "string" },
      "subtotal": number
    },
    "brandAlignment": {
      "brandVisualIdentity": { "score": number, "reasoning": "string" },
      "brandVoiceCommunication": { "score": number, "reasoning": "string" },
      "audienceResonance": { "score": number, "reasoning": "string" },
      "marketPositioningSupport": { "score": number, "reasoning": "string" },
      "subtotal": number
    },
    "contentQuality": {
      "technicalExecution": { "score": number, "reasoning": "string" },
      "visualImpact": { "score": number, "reasoning": "string" },
      "channelOptimization": { "score": number, "reasoning": "string" },
      "subtotal": number
    }
  },
  "finalScore": number,
  "reasoning": "string"
}
`

      const messages: any[] = [
        {
          role: "system",
          content: "You are an expert at evaluating image generation quality and prompt-to-image adherence. Always respond with valid JSON."
        },
        {
          role: "user",
          content: [
            { type: "text", text: prompt }
          ]
        }
      ]

      // Add image if available
      if (imageContent) {
        messages[1].content.push({
          type: "image_url",
          image_url: { url: imageContent }
        })
      }

      const response = await llmGateway.generateWithVision({
        role: "user",
        content: messages[1].content
      }, {
        model: "gpt-4o",
        temperature: 0.3,
        maxTokens: 1500,
        jsonMode: true,
      })

      const evaluation = JSON.parse(response.content)

      // Calculate weighted final score based on new criteria
      const promptMatchingScore = (
        evaluation.criteria.promptMatching.subjectFidelity.score * 0.3 +
        evaluation.criteria.promptMatching.detailAccuracy.score * 0.25 +
        evaluation.criteria.promptMatching.styleAdherence.score * 0.25 +
        evaluation.criteria.promptMatching.compositionAlignment.score * 0.2
      )

      const brandAlignmentScore = (
        evaluation.criteria.brandAlignment.brandVisualIdentity.score * 0.3 +
        evaluation.criteria.brandAlignment.brandVoiceCommunication.score * 0.25 +
        evaluation.criteria.brandAlignment.audienceResonance.score * 0.25 +
        evaluation.criteria.brandAlignment.marketPositioningSupport.score * 0.2
      )

      const contentQualityScore = (
        evaluation.criteria.contentQuality.technicalExecution.score * 0.4 +
        evaluation.criteria.contentQuality.visualImpact.score * 0.35 +
        evaluation.criteria.contentQuality.channelOptimization.score * 0.25
      )

      const finalScore = Math.round(
        (promptMatchingScore * 0.35) +
        (brandAlignmentScore * 0.35) +
        (contentQualityScore * 0.30)
      )

      return {
        score: finalScore,
        reasoning: evaluation.reasoning,
        executionTime: Date.now() - startTime,
        status: "success",
        details: {
          criteria: evaluation.criteria,
          promptMatchingScore: Math.round(promptMatchingScore),
          brandAlignmentScore: Math.round(brandAlignmentScore),
          contentQualityScore: Math.round(contentQualityScore),
          llmResponse: response,
        },
      }
    } catch (error) {
      return {
        score: 0,
        reasoning: `Error evaluating subject adherence with LLM: ${error instanceof Error ? error.message : "Unknown error"}`,
        executionTime: Date.now() - startTime,
        status: "error",
        error: error instanceof Error ? error.message : "Unknown error",
      }
    }
  }

  private getMimeType(filePath: string): string {
    const ext = path.extname(filePath).toLowerCase()
    switch (ext) {
      case '.jpg':
      case '.jpeg':
        return 'image/jpeg'
      case '.png':
        return 'image/png'
      case '.gif':
        return 'image/gif'
      case '.webp':
        return 'image/webp'
      default:
        return 'image/jpeg'
    }
  }
}
